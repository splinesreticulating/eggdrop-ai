# Eggdrop AI v2.0.0 - Vector Memory Release

## üöÄ Major Features

### Vector Memory System
The bot now has a **complete conversational memory** using vector embeddings and semantic search:

- **Full channel awareness**: Stores ALL channel messages, not just direct mentions
- **Semantic search**: Finds relevant past messages using vector similarity (Xenova/all-MiniLM-L6-v2)
- **Hybrid context**: Combines recent messages + semantically similar messages
- **Chronological ordering**: Context presented in proper timeline for coherent recall
- **Persistent storage**: SQLite database with sqlite-vec extension for vector operations
- **Configurable retention**: Default 90-day message retention (configurable or unlimited)

### New Endpoints

- `POST /store` - Passive message storage without LLM response (used for all channel messages)
- `POST /chat` - Enhanced to retrieve context from vector memory before generating responses

### How It Works

1. **All channel messages** ‚Üí stored in vector memory via `/store` endpoint
2. **When mentioned** ‚Üí bot retrieves relevant context (recent + similar messages)
3. **LLM response** ‚Üí generated with full conversational awareness
4. **Bot remembers** ‚Üí facts, preferences, and conversations over time

## üîß Improvements

### Performance & Reliability
- Increased API timeout: 30s ‚Üí 90s (handles slow free tier models)
- Increased Eggdrop timeout: 45s ‚Üí 100s
- Fixed message duplication in context (3x ‚Üí 2x)
- Async message storage (doesn't block responses)

### Configuration
New environment variables for vector memory:
- `MEMORY_ENABLED` - Enable/disable memory system (default: true)
- `MEMORY_DB_PATH` - Database file path
- `MEMORY_TOP_K` - Max similar messages to retrieve (default: 15)
- `MEMORY_RECENT_COUNT` - Recent messages to include (default: 5)
- `MEMORY_RETENTION_DAYS` - Message retention period (default: 90)
- `DEBUG_LOG_REQUESTS` - Log full context sent to LLM (for debugging)

### Model Configuration
- Increased `max_tokens`: 100 ‚Üí 300 tokens
- Updated production model: `xiaomi/mimo-v2-flash:free`
- System prompt improvements for memory usage

## üì¶ Installation Notes

### New Requirements
```bash
cd gateway
npm run setup  # Downloads sqlite-vec extension
```

On first run, the embedding model (~90MB) will be downloaded automatically. This takes 10-30 seconds and only happens once.

### Upgrading from v1.0.0

1. **Pull latest code**:
   ```bash
   git pull origin main
   ```

2. **Install new dependencies**:
   ```bash
   cd gateway
   npm install
   npm run setup  # Download sqlite-vec extension
   ```

3. **Update Eggdrop script**:
   ```bash
   cp eggdrop/eggdrop-ai.tcl /path/to/eggdrop/scripts/
   ```

4. **Rebuild and restart gateway**:
   ```bash
   npm run build
   npm start  # or restart your systemd/pm2 service
   ```

5. **Rehash Eggdrop**:
   ```
   .rehash
   ```

### Configuration Migration

The `.env` file has new optional variables. Your existing configuration will continue to work with defaults:

```bash
# Optional - vector memory is enabled by default
MEMORY_ENABLED=true
MEMORY_RETENTION_DAYS=90
```

## üìù Documentation Updates

- Comprehensive README updates explaining vector memory architecture
- Updated CLAUDE.md with implementation details
- New troubleshooting sections for memory-related issues
- Enhanced testing instructions

## üêõ Bug Fixes

- Fixed TypeScript compilation error with Pipeline type
- Fixed message duplication causing 3x context repetition
- Improved error handling for memory system failures
- Better timeout handling for slow API responses

## üîç Example Usage

**Teaching the bot facts:**
```
<user> @bot my favorite color is crimson
<bot> Noted.
... many messages later ...
<user> @bot what's my favorite color?
<bot> Crimson.
```

**Context-aware conversations:**
```
<alice> I'm going to the store
<bob> Can you get milk?
<alice> @bot what did bob ask me to get?
<bot> Milk.
```

The bot now maintains full conversational context and can recall information from anywhere in the channel history.

## ‚ö†Ô∏è Breaking Changes

None - this is a backward-compatible release. The memory system is opt-in via environment variables.

## üìä Performance Impact

- **Storage**: ~1-2KB per message (text + 384-dim vector embedding)
- **Memory**: ~90MB for embedding model (loaded once on startup)
- **Response time**: +10-50ms for context retrieval (negligible)
- **Startup time**: +10-30 seconds on first run (model download)

## üôè Credits

Built with:
- [OpenRouter](https://openrouter.ai/) - LLM API aggregation
- [transformers.js](https://github.com/xenova/transformers.js) - Embedding model
- [sqlite-vec](https://github.com/asg017/sqlite-vec) - Vector similarity search
- [better-sqlite3](https://github.com/WiseLibs/better-sqlite3) - SQLite driver

---

**Full Changelog**: https://github.com/splinesreticulating/eggdrop-ai/compare/v1.0.0...v2.0.0
